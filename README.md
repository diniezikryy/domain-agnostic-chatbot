# Domain-Agnostic Chatbot

A production-ready Python CLI application for querying documents across different domains using hybrid FAISS + BM25 search with intelligent query decomposition and zero-trust response generation.

## Overview

This chatbot system can work with different document sets (insurance policies, legal contracts, technical manuals, etc.) by implementing a batch management system. Users can easily switch between different document domains and ask questions specific to each domain.

**Key Innovation**: Advanced RAG pipeline with query decomposition, balanced retrieval, and evidence verification to ensure accurate, comprehensive, and cited responses.

## Features

- **Multi-format support**: PDF, DOCX, TXT, MD files
- **Hybrid search**: FAISS vector search + BM25 keyword search
- **Intelligent query decomposition**: Complex questions broken into focused sub-queries
- **Balanced retrieval**: Fair representation from all sources in comparisons
- **Zero-trust response generation**: Strict evidence requirements, no hallucinations
- **Source citations**: Every claim backed by document references
- **Evidence verification**: System acknowledges when data is insufficient
- **Batch management**: Organize documents by domain
- **CLI interface**: Simple command-line interaction
- **Evaluation suite**: Automated testing for quality assurance
- **Domain-agnostic**: No hardcoded domain-specific logic

## Performance Metrics

Based on comprehensive evaluation:
- **Test Pass Rate**: 100% (8/8 tests)
- **Accuracy Score**: 95.7% (45/47 checks)
- **Response Time**: 7-16 seconds (depending on complexity)
- **Memory Usage**: <500MB per query
- **Retrieval Balance**: 5:6 to 10:10 for comparison queries

## Quick Start

### 1. Setup Environment
```bash
# Clone or create project directory
cd domain-agnostic-chatbot

# Install dependencies
pip install -r requirements.txt

# Set OpenAI API key in .env file
echo "OPENAI_API_KEY=your-api-key-here" > .env
```

### 2. Add Documents
```bash
# Create domain directories and add your documents
mkdir -p documents/insurance
cp your_insurance_docs/*.pdf documents/insurance/

mkdir -p documents/legal
cp your_legal_docs/*.docx documents/legal/
```

### 3. Create Document Batches
```bash
# Process insurance documents
python setup_batch.py insurance
# Output: âœ… Batch created successfully! (182 chunks from 4 documents)

# Process legal documents
python setup_batch.py legal
```

### 4. Query Documents
```bash
# Ask questions using default batch
python main.py "What medical conditions are covered?"

# Ask questions using specific batch
python main.py --batch insurance "Can I claim for diabetes?"
python main.py --batch legal "What are the termination clauses?"

# Complex comparison queries
python main.py --batch insurance "What are the pros and cons of SingLife vs FWD?"

# List available batches
python main.py --list-batches

# Get batch information
python main.py --batch-info insurance
```

## CLI Commands

### Core Commands
```bash
# Ask a question (uses default batch)
python main.py "Your question here"

# Ask with specific batch
python main.py --batch  "Your question here"

# List available batches
python main.py --list-batches

# Get batch information
python main.py --batch-info 

# Set default batch
python main.py --set-default 
```

### Batch Management Commands
```bash
# Create new batch from documents
python setup_batch.py 

# Recreate existing batch
python setup_batch.py  --rebuild

# Delete batch
python setup_batch.py  --delete

# Use custom source directory
python setup_batch.py  --source /path/to/documents
```

### Evaluation Commands
```bash
# Run comprehensive evaluation tests
python tests/test_queries.py --batch insurance

# Expected output: Tests Passed: 8/8 (100%), Score: 95.7%
```

## Directory Structure
```
domain-agnostic-chatbot/
â”œâ”€â”€ main.py                        # CLI entry point
â”œâ”€â”€ setup_batch.py                 # Batch creation script
â”œâ”€â”€ batch_manager.py               # Core batch management
â”œâ”€â”€ document_processor.py          # Document processing
â”œâ”€â”€ query_processor.py             # Query processing (with decomposition & verification)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_handlers.py           # PDF, DOCX, TXT processors
â”‚   â”œâ”€â”€ embeddings.py              # Text embedding utilities
â”‚   â””â”€â”€ search.py                  # FAISS + BM25 hybrid search
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py                # Configuration management
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_queries.py            # Evaluation test suite
â”œâ”€â”€ documents/                     # User document input
â”‚   â”œâ”€â”€ insurance/                 # Insurance documents
â”‚   â”œâ”€â”€ legal/                     # Legal documents
â”‚   â””â”€â”€ technical/                 # Technical manuals
â”œâ”€â”€ batches/                       # Generated document batches
â”‚   â”œâ”€â”€ batch_registry.json        # Central batch registry
â”‚   â”œâ”€â”€ insurance/                 # Processed insurance batch
â”‚   â”‚   â”œâ”€â”€ faiss_index/
â”‚   â”‚   â”œâ”€â”€ bm25_index.pkl
â”‚   â”‚   â””â”€â”€ metadata.json
â”‚   â””â”€â”€ legal/                     # Processed legal batch
â”œâ”€â”€ .env                           # API keys (create this)
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ SYSTEM_OVERVIEW.md             # Technical deep-dive
```

## How It Works

### **1. Document Processing**
Documents are processed into text chunks with metadata:
- **Chunking**: 800-character chunks with 100-char overlap
- **Metadata**: Filename, page number, year extraction
- **Embeddings**: OpenAI text-embedding-3-small (1536 dimensions)

### **2. Index Creation**
Two complementary indexes are built:
- **FAISS**: Semantic search using vector embeddings
- **BM25**: Keyword search using term frequency

### **3. Intelligent Query Processing**
When you ask a question:
1. **Query Decomposition**: Complex questions â†’ 4-10 focused sub-questions
2. **Balanced Retrieval**: Equal chunks from all sources in comparisons
3. **Hybrid Search**: Combines FAISS (60%) + BM25 (40%) scores
4. **Evidence Verification**: Checks if sufficient data exists before answering

### **4. Zero-Trust Response Generation**
Responses are generated with strict rules:
- âœ… Every claim must cite sources: `[Source X, Page Y]`
- âœ… Distinguishes "not mentioned" from "explicitly excluded"
- âœ… Acknowledges missing data: "The documents don't provide information about X"
- âœ… Never hallucinates features not in documents

### **5. Quality Assurance**
Built-in evaluation suite ensures:
- Balanced retrieval from multiple sources
- Proper source citations
- No prohibited claims without evidence
- Acknowledgment of data limitations

## Configuration

### Environment Variables
- `OPENAI_API_KEY`: Required for embeddings and response generation

### Tunable Parameters (`config/settings.py`)
```python
# Document Processing
chunk_size = 800              # Characters per chunk
chunk_overlap = 100           # Overlap to preserve context

# Search Configuration
faiss_weight = 0.6           # Semantic search weight
bm25_weight = 0.4            # Keyword search weight
top_k = 10                   # Chunks per sub-query

# Retrieval for Comparisons
max_per_policy = 10          # Chunks per source in comparisons

# Response Generation
max_tokens = 1500            # GPT response length
temperature = 0.1            # Lower = more factual
```

## Architecture Deep-Dive

### Query Processing Pipeline
```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Query Analysis                   â”‚
â”‚    â€¢ Detect comparison vs single    â”‚
â”‚    â€¢ Identify mentioned sources     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Query Decomposition (GPT-4o)    â”‚
â”‚    â€¢ Complex â†’ 4-10 sub-questions   â”‚
â”‚    â€¢ Balanced for comparisons       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Hybrid Search (per sub-query)   â”‚
â”‚    â€¢ FAISS: Semantic similarity     â”‚
â”‚    â€¢ BM25: Keyword matching         â”‚
â”‚    â€¢ Combine: 60% FAISS + 40% BM25  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Balanced Retrieval               â”‚
â”‚    â€¢ 10 chunks per source           â”‚
â”‚    â€¢ Deduplication                  â”‚
â”‚    â€¢ Total: 20 chunks for context   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Evidence Verification            â”‚
â”‚    â€¢ Check all sources present      â”‚
â”‚    â€¢ Return error if insufficient   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Response Generation (GPT-4o-mini)â”‚
â”‚    â€¢ Zero-trust prompt              â”‚
â”‚    â€¢ Cite every claim               â”‚
â”‚    â€¢ Comprehensive coverage         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
          Final Answer
```

## Performance

### Benchmark Results (Insurance Domain, 182 chunks)

| Metric | Value | Target |
|--------|-------|--------|
| **Query Decomposition** | 4-10 sub-queries | âœ… Working |
| **Retrieval Time** | 2-5s | <6s âœ… |
| **Response Generation** | 3-10s | <6s âœ… |
| **Total Response Time** | 7-16s | <20s âœ… |
| **Memory Usage** | ~300MB | <500MB âœ… |
| **Test Pass Rate** | 100% (8/8) | >90% âœ… |
| **Accuracy Score** | 95.7% | >90% âœ… |
| **Retrieval Balance** | 5:6 to 10:10 | Balanced âœ… |

### Comparison with Original System

| Feature | Original | Enhanced |
|---------|----------|----------|
| Query Decomposition | âŒ None | âœ… 4-10 sub-queries |
| Balanced Retrieval | âŒ Biased (4:1) | âœ… Balanced (10:10) |
| Evidence Verification | âŒ None | âœ… Pre-answer checks |
| Source Citations | âš ï¸ Sometimes | âœ… Always |
| Hallucination Prevention | âš ï¸ Partial | âœ… Zero-trust prompts |
| Test Pass Rate | 87.5% | 100% |

## Examples

### Insurance Policy Queries

**Simple Query:**
```bash
$ python main.py --batch insurance "What is covered for diabetes?"

Response:
The policy covers diabetic conditions including diabetic nephropathy, 
diabetic ketoacidosis, and complications such as leg amputation 
[Source 3, Page 4]. The SingLife Essential Critical Illness II 
explicitly mentions coverage for Type 2 diabetes [Source 1, Page 3]...
```

**Comparison Query:**
```bash
$ python main.py --batch insurance "What are the pros and cons of SingLife vs FWD?"

Query type: Comparison
Policies mentioned: ['singlife', 'fwd']
Decomposed into 10 sub-queries:
  1. What are ALL the unique benefits of SingLife...
  2. What are ALL the unique benefits of FWD...
  ...

=== Retrieval Balance ===
SINGLIFE: 10 chunks
FWD: 10 chunks
========================

Response:
Pros of SingLife Essential Critical Illness II:
1. Coverage for Pre-existing Conditions [Source 1]
2. No Claim Reward (20% premium return) [Source 3]
3. Hassle-free application (6 questions) [Source 2]
...

Pros of FWD Critical Illness Plus:
1. Auto-reload Benefit (12-month premium waiver) [Source 8]
2. ICU Benefit rider option [Source 10]
3. Early Cancer/Heart Attack/Stroke benefit [Source 9]
...
```

**Handling Missing Data:**
```bash
$ python main.py --batch insurance "What are the claim approval rates?"

Response:
The documents do not provide information about claim approval rates 
for SingLife and FWD. Specifically, the documents [Sources 1-12] do 
not include any statistics or details regarding claim approval rates...
```

### Legal Contract Queries
```bash
python main.py --batch legal "What are the termination clauses?"
python main.py --batch legal "What are the payment terms?"
python main.py --batch legal "Who owns intellectual property?"
```

### Technical Manual Queries
```bash
python main.py --batch technical "How do I install the software?"
python main.py --batch technical "What are the system requirements?"
python main.py --batch technical "How do I troubleshoot errors?"
```

## Evaluation & Testing

### Running Tests
```bash
# Run full evaluation suite
python tests/test_queries.py --batch insurance

# Output:
# ================================================================================
# INSURANCE POLICY RAG EVALUATION
# ================================================================================
# [Test 1/8] Comparison - Unique Exclusions
# âœ… PASSED (7/8 checks)
# ...
# Tests Passed: 8/8 (100%)
# Overall Score: 45/47 (95.7%)
```

### Test Categories
1. **Comparison Queries**: Unique exclusions, price differences, pros/cons
2. **Coverage Queries**: What's covered, differences between policies
3. **Recommendation Queries**: Main reasons to choose one policy
4. **Single Policy Queries**: Coverage details, claim process
5. **Limitation Handling**: Queries about unavailable data

### Quality Checks
- âœ… Must contain required terms
- âœ… Must cite both policies in comparisons
- âœ… Must acknowledge limitations when data missing
- âœ… Must have source citations
- âœ… Must not make prohibited claims
- âœ… Must acknowledge different customer profiles

## Advanced Features

### Query Decomposition
Complex queries are automatically broken down:
- **Input**: "What are the pros and cons of A vs B?"
- **Decomposed**: 10 focused sub-questions covering all aspects
- **Result**: Comprehensive, balanced answers

### Evidence Verification
System checks data availability before answering:
- Detects comparison queries requiring multiple sources
- Verifies all mentioned sources are present in results
- Returns helpful error if data insufficient: "I can only find information about X, cannot compare without Y"

### Zero-Trust Prompts
GPT is given strict instructions:
- Never make claims without source citations
- Distinguish "not mentioned" from "explicitly excluded"
- Acknowledge when information is missing
- Never assume silence means exclusion

### Balanced Retrieval
For comparison queries:
- Retrieves equal chunks from each source (10:10)
- Prevents bias toward one source
- Ensures fair, comprehensive comparisons

## Roadmap

### âœ… Phase 1: Core CLI Application (COMPLETE)
- Pure Python CLI implementation
- Hybrid FAISS + BM25 search
- Query decomposition
- Balanced retrieval
- Evidence verification
- Evaluation suite
- **Status**: Production-ready, 100% test pass rate

### ğŸš§ Phase 2: Web Integration (Planned)
- FastAPI server for programmatic access
- RESTful APIs for batch management
- Web-based document upload interface
- Real-time streaming responses

### ğŸ“‹ Phase 3: MCP Integration (Planned)
- MCP server exposing domain switching tools
- Integration with Claude Code
- Enhanced tool descriptions
- Multi-turn conversation support

### ğŸ”® Phase 4: Advanced Features (Future)
- Real-time document updates and re-indexing
- Advanced analytics and usage tracking
- Multi-user support with access controls
- Cloud deployment options (AWS, GCP, Azure)
- Custom fine-tuned embeddings
- Multi-language support

## Troubleshooting

### Common Issues

1. **JSON Decomposition Error**
```
   Error: 'messages' must contain the word 'json'
```
   - **Solution**: Ensure you're using the updated `query_processor.py` with JSON format instructions

2. **No embeddings generated**
   - Check `OPENAI_API_KEY` is set in `.env` file
   - Verify internet connection
   - Check API quota: https://platform.openai.com/usage

3. **Document processing fails**
   - Ensure file format is supported (PDF, DOCX, TXT, MD)
   - Check file permissions
   - Verify file is not corrupted
   - Install missing dependencies: `pip install PyPDF2 python-docx`

4. **Batch not found**
   - Use `--list-batches` to see available batches
   - Ensure batch was created successfully
   - Check `batches/batch_registry.json` exists

5. **Slow performance**
   - Check available memory (need ~500MB)
   - Reduce `max_per_policy` in settings
   - Use smaller batch sizes (<200 documents)

6. **Imbalanced retrieval**
   - Check document distribution in batch
   - Ensure filenames contain policy identifiers
   - Review `=== Retrieval Balance ===` output

## Best Practices

### Document Organization
```bash
# Good: Clear domain separation
documents/
â”œâ”€â”€ insurance/
â”‚   â”œâ”€â”€ singlife_policy.pdf
â”‚   â””â”€â”€ fwd_policy.pdf
â”œâ”€â”€ legal/
â”‚   â””â”€â”€ contract.docx
â””â”€â”€ technical/
    â””â”€â”€ manual.md

# Bad: Mixed domains
documents/
â”œâ”€â”€ all_files/
    â”œâ”€â”€ insurance.pdf
    â”œâ”€â”€ legal.docx
    â””â”€â”€ manual.md  # Hard to separate!
```

### Naming Conventions
- Use descriptive filenames: `FWD_Critical_Illness_2023.pdf` âœ…
- Avoid generic names: `document1.pdf` âŒ
- Include identifiers: Company name, year, product

### Query Best Practices
- **Good**: "What are the differences between SingLife and FWD coverage for diabetes?"
- **Better**: "Compare the diabetic conditions benefits in SingLife Essential Critical Illness II versus FWD Critical Illness Plus"
- **Avoid**: "Tell me everything" (too vague)

## Contributing

This is a foundation for building domain-agnostic document query systems. The modular architecture allows for easy extension and customization.

### Key Extension Points
- **New file formats**: Add handlers in `utils/file_handlers.py`
- **Custom search logic**: Modify `utils/search.py`
- **Query processing**: Enhance `query_processor.py`
- **New CLI commands**: Extend `main.py`
- **Additional tests**: Add cases in `tests/test_queries.py`

### Development Setup
```bash
# Install dev dependencies
pip install -r requirements.txt
pip install pytest black flake8

# Run tests
python tests/test_queries.py

# Format code
black *.py utils/*.py

# Lint
flake8 *.py utils/*.py
```

## Technical Documentation

For detailed technical documentation, architecture diagrams, and algorithm explanations, see:
- **[SYSTEM_OVERVIEW.md](SYSTEM_OVERVIEW.md)** - Complete technical deep-dive

## License

This project is provided as-is for educational and commercial use.

## Support

For issues, questions, or feature requests:
1. Check the Troubleshooting section above
2. Review SYSTEM_OVERVIEW.md for technical details
3. Run evaluation tests to diagnose issues
4. Check `batches/batch_registry.json` for batch configuration

---